setMethod(
	f = "print",
	signature = signature(x = 'polymirtClass'),
	definition = function(x, ...){
		cat("\nCall:\n", paste(deparse(x@Call), sep = "\n", collapse = "\n"), 
			"\n\n", sep = "")
		cat("Full-information factor analysis with ", ncol(x@F), " factor",
			if(ncol(x@F)>1) "s", "\n", sep="")
		if(x@converge == 1)	
			cat("Converged in ", x@cycles, " iterations.\n", sep="")
		else 	
			cat("Estimation stopped after ", x@cycles, " iterations.\n", sep="")		
		if(length(x@logLik) > 0){
			cat("Log-likelihood = ", x@logLik,", SE = ",round(x@SElogLik,3), "\n",sep='')			
			cat("AIC =", x@AIC, "\n")
			if(x@p < 1)
				cat("G^2 = ", round(x@G2,2), ", df = ", 
					x@df, ", p = ", round(x@p,4), "\n", sep="")
			else 
				cat("G^2 = ", NA, ", df = ", 
					x@df, ", p = ", NA, "\n", sep="")	
		}					
	} 
)

setMethod(
	f = "show",
	signature = signature(object = 'polymirtClass'),
	definition = function(object){
		cat("\nCall:\n", paste(deparse(object@Call), sep = "\n", collapse = "\n"), 
			"\n\n", sep = "")
		cat("Full-information factor analysis with ", ncol(object@F), " factor",
			if(ncol(object@F)>1) "s", "\n", sep="")
		if(object@converge == 1)	
			cat("Converged in ", object@cycles, " iterations.\n", sep="")
		else 	
			cat("Estimation stopped after ", object@cycles, " iterations.\n", sep="")	
		if(length(object@logLik) > 0){
			cat("Log-likelihood = ", object@logLik,", SE = ",round(object@SElogLik,3), "\n",sep='')			
			cat("AIC =", object@AIC, "\n")
			if(object@p < 1)
				cat("G^2 = ", round(object@G2,2), ", df = ", 
					object@df, ", p = ", round(object@p,4), "\n", sep="")
			else 
				cat("G^2 = ", NA, ", df = ", 
					object@df, ", p = ", NA, "\n", sep="")
		}			
	} 
)

setMethod(
	f = "summary",
	signature = 'polymirtClass',
	definition = function(object, rotate = 'varimax', suppress = 0, digits = 3, ...){
		nfact <- ncol(object@F)
		if (rotate == 'none' || nfact == 1) {
			F <- object@F
			F[abs(F) < suppress] <- NA
			h2 <- as.matrix(object@h2)    	
			SS <- apply(F^2,2,sum)
			colnames(h2) <- "h2"	
			colnames(F) <- names(SS) <- paste("F_", 1:ncol(F),sep="")
			cat("\nUnrotated factor loadings: \n\n")
			loads <- round(cbind(F,h2),digits)
			print(loads)	    	 
			cat("\nSS loadings: ",round(SS,digits), "\n")
			cat("Proportion Var: ",round(SS/nrow(F),digits), "\n")
			invisible(list(F,h2))
		} else {	
			F <- object@F
			h2 <- as.matrix(object@h2)		
			colnames(F) <- paste("F_", 1:ncol(F),sep="")
			colnames(h2) <- "h2"		
			cat("\nRotation: ", rotate, "\n")
			rotF <- Rotate(F,rotate)
			SS <- apply(rotF$loadings^2,2,sum)
			L <- rotF$loadings
			L[abs(L) < suppress] <- NA	
			loads <- round(cbind(L,h2),digits)		
			cat("\nRotated factor loadings: \n\n")
			print(loads,digits)		
			if(attr(rotF, "oblique")){
				cat("\nFactor correlations: \n\n")
				Phi <- rotF$Phi	  
				Phi <- round(Phi, digits)
				colnames(Phi) <- rownames(Phi) <- colnames(F)
				print(Phi)			    
			}		
			cat("\nSS loadings: ",round(SS,digits), "\n")		
			if(!attr(rotF, "oblique")) 
				cat("Proportion Var: ",round(SS/nrow(F),digits), "\n")
			if(any(h2 > 1)) 
				warning("Solution has heywood cases. Interpret with caution.") 
			invisible(list(rotF$loadings,h2))  
		}  
	}
)

setMethod(
	f = "coef",
	signature = 'polymirtClass',
	definition = function(object, SE = TRUE, digits = 3, ...){  
		nfact <- ncol(object@Theta)	
		a <- matrix(object@pars[ ,1:nfact],ncol=nfact)
		d <- matrix(object@pars[,(nfact+1):ncol(object@pars)],
			ncol = ncol(object@pars)-nfact)    
		A <- sqrt(apply(a^2,1,sum))
		B <- -d/A  
		if (nfact > 1){  
			parameters <- cbind(object@pars,object@guess,A,B)
			SEs <- object@SEpars	
			colnames(parameters) <- c(paste("a_",1:nfact,sep=""),
				paste("d_",1:(ncol(object@pars)-nfact),sep=""),"guess","mvdisc",
				paste("mvint_",1:(ncol(object@pars)-nfact),sep=""))	
			colnames(SEs) <- c(paste("a_",1:nfact,sep=""),
				paste("d_",1:(ncol(object@pars)-nfact),sep=""),"guess")		
			cat("\nUnrotated parameters, multivariate discrimination and intercept: \n\n")
			print(round(parameters, digits))
			if(SE){
				cat("\nStd. Errors: \n\n")	
				print(round(SEs, digits))
			}				
		} else {
			parameters <- cbind(object@pars,object@guess)
			SEs <- object@SEpars	
			colnames(parameters) <- colnames(SEs) <- c(paste("a_",1:nfact,sep=""),
				paste("d_",1:(ncol(object@pars)-nfact),sep=""),"guess")			
			cat("\nParameter slopes and intercepts: \n\n")	
			print(round(parameters, digits))
			if(SE){
				cat("\nStd. Errors: \n\n")	
				print(round(SEs, digits))
			}
		}
		invisible(parameters)
	}
)

setMethod(
	f = "plot",
	signature = signature(x = 'polymirtClass', y = "missing"),
	definition = function(x, y, npts = 50, 
		rot = list(xaxis = -70, yaxis = 30, zaxis = 10))
	{  
		type = 'curve'
		rot <- list(x = rot[[1]], y = rot[[2]], z = rot[[3]])
		K <- x@K		
		nfact <- ncol(x@Theta)
		if(nfact >2) stop("Can't plot high dimensional solutions.")
		a <- as.matrix(x@pars[ ,1:nfact])
		d <- as.matrix(x@pars[ ,(nfact+1):ncol(x@pars)])	
		guess <- x@guess
		guess[is.na(guess)] <- 0
		A <- as.matrix(sqrt(apply(a^2,1,sum)))	
		theta <- seq(-4,4,length.out=npts)
		Theta <- thetaComb(theta, nfact)
		info <- rep(0,nrow(Theta))
		for(j in 1:length(K)){
			if(K[j] > 2){
				P <- P.poly(a[j,], d[j,],Theta, itemexp = FALSE)		
				for(i in 1:K[j]){
					w1 <- P[,i]*(1-P[,i])*A[j]
					w2 <- P[,i+1]*(1-P[,i+1])*A[j]
					I <- ((w1 - w2)^2) / (P[,i] - P[,i+1]) * P[,i]
					info <- info + I
				}
			} else {
				P <- P.mirt(a[j,], d[j,],Theta, guess[j])
				Pstar <- P.mirt(a[j,], d[j,],Theta, 0)
				info <- info + A[j]^2 * P * (1-P) * Pstar/P
			}			
		}		
		plt <- data.frame(cbind(info,Theta))
		if(nfact > 1){
			require(lattice)			
			colnames(plt) <- c("info", "Theta1", "Theta2")
			wireframe(info ~ Theta1 + Theta2, data = plt, main = "Item Information", 
				zlab = "I", xlab = "Theta 1", ylab = "Theta 2", scales = list(arrows = FALSE),
				screen = rot)	
		} else 
			plot(Theta, info, type='l',main = 'Item Information', xlab = 'Theta', ylab='Information')
	}	  
)	

setMethod(
	f = "residuals",
	signature = signature(object = 'polymirtClass'),
	definition = function(object, digits = 3, ...){ 	
		fulldata <- object@fulldata	
		data <- object@data
		data[data==99] <- NA
		N <- nrow(fulldata)
		K <- object@K
		J <- length(K)
		nfact <- ncol(object@F)
		theta <- seq(-4,4, length.out = round(20/nfact))
		Theta <- thetaComb(theta,nfact)
		lambdas <- matrix(object@pars[,1:nfact], J)
		zetas <- as.vector(t(object@pars[,(nfact+1):ncol(object@pars)]))
		zetas <- na.omit(zetas)
		guess <- object@guess
		guess[is.na(guess)] <- 0	
		Ksums <- cumsum(K) - 1	
		itemloc <- object@itemloc
		res <- matrix(0,J,J)
		diag(res) <- NA
		colnames(res) <- rownames(res) <- colnames(data)
		prior <- dmvnorm(Theta,rep(0,nfact),diag(nfact))
		prior <- prior/sum(prior)
		loc <- loc2 <- 1	
		for(i in 1:J){
			if(i > 1) loc <- loc + K[i-1] - 1	
			loc2 <- 1
			for(j in 1:J){			
				if(i < j){
					if(K[i] > 2) P1 <- P.poly(lambdas[i,],zetas[loc:(loc+K[i]-2)],Theta,itemexp=TRUE)
					else { 
						P1 <- P.mirt(lambdas[i,],zetas[loc], Theta, guess[i])
						P1 <- cbind(1 - P1, P1)
					}	
					if(K[j] > 2) P2 <- P.poly(lambdas[j,],zetas[loc2:(loc2+K[j]-2)],Theta,itemexp=TRUE)
					else {
						P2 <- P.mirt(lambdas[j,],zetas[loc2], Theta, guess[j])	
						P2 <- cbind(1 - P2, P2)
					}
					tab <- table(data[,i],data[,j])		
					Etab <- matrix(0,K[i],K[j])
					for(k in 1:K[i])
						for(m in 1:K[j])						
							Etab[k,m] <- N * sum(P1[,k] * P2[,m] * prior)	
					s <- gamma.cor(tab) - gamma.cor(Etab)
					if(s == 0) s <- 1				
					res[j,i] <- sum(((tab - Etab)^2)/Etab) /
						((K[i] - 1) * (K[j] - 1)) * sign(s)
					res[i,j] <- sqrt( abs(res[j,i]) / (N - min(c(K[i],K[j]) - 1)))	
				}
			loc2 <- loc2 + K[j] - 1 	
			}
		}	
		cat("LD matrix:\n\n")	
		res <- round(res,digits)
		res
	}
)

setMethod(
	f = "logLik",
	signature = signature(object = 'polymirtClass'),
	definition = function(object, draws = 2000, G2 = TRUE){	
		nfact <- ncol(object@Theta)
		N <- nrow(object@Theta)
		J <- length(object@K)
		pars <- object@pars
		lambdas <- pars[,1:nfact]
		zetas <- pars[,(nfact+1):ncol(pars)]
		zetas <- t(zetas)[!is.na(t(zetas))]		
		mu <- rep(0,nfact)
		sigma <- diag(nfact)		
		LL <- matrix(0,N,draws)		
		guess <- object@guess
		guess[is.na(guess)] <- 0
		K <- object@K
		df <- -nfact*J - sum(K - 1) - 1
		fulldata <- object@fulldata
		for(i in 1:draws){
			theta <- rmvnorm(N,mu,sigma)				
			LL[,i] <- .Call('logLik', 					
						as.numeric(lambdas),
						as.numeric(zetas),
						as.numeric(guess),
						as.numeric(theta),
						as.integer(fulldata),
						as.integer(object@itemloc-1),
						as.integer(object@K),
						as.integer(J),
						as.integer(N),
						as.integer(nfact))		
		}		
		rwmeans <- rowMeans(LL)
		logLik <- sum(log(rwmeans))		
		pats <- apply(fulldata,1,paste,collapse = "/")
		freqs <- table(pats)
		nfreqs <- length(freqs)		
		r <- as.vector(freqs)
		ncolfull <- ncol(fulldata)
		tabdata <- unlist(strsplit(cbind(names(freqs)),"/"))
		tabdata <- matrix(as.numeric(tabdata),nfreqs,ncolfull,TRUE)
		tabdata <- cbind(tabdata,r)		
		logN <- 0
		logr <- rep(0,length(r))
		for (i in 1:N) logN <- logN + log(i)
		for (i in 1:length(r)) 
			for (j in 1:r[i]) 
				logr[i] <- logr[i] + log(j) 
		if(sum(logr) != 0)								
			logLik <- logLik + logN/sum(logr)		
		SElogLik <- sqrt(var(log(rwmeans)) / draws)
		df <- (length(r) - 1) - nfact*J - sum(K - 1) + nfact*(nfact - 1)/2
		AIC <- (-2) * logLik + 2 * (length(r) - df - 1)
		if(G2){				
			data <- object@data
			if(any(is.na(data))){
				object@G2 <- 0	
				object@p <- 1					
			} else {
				pats <- apply(data,1,paste,collapse = "/")			
				freqs <- table(pats)
				nfreqs <- length(freqs)		
				r <- as.vector(freqs)
				ncolfull <- ncol(data)
				tabdata <- unlist(strsplit(cbind(names(freqs)),"/"))
				tabdata <- matrix(as.numeric(tabdata),nfreqs,ncolfull,TRUE)
				tabdata <- cbind(tabdata,r)							
				for (j in 1:nrow(tabdata)){          
					TFvec <- colSums(ifelse(t(data) == tabdata[j,1:ncolfull],1,0)) == ncolfull        
					rwmeans[TFvec] <- rwmeans[TFvec]/r[j]
				}
				G2 <- 2 * sum(log(1/(N*rwmeans)))
				p <- 1 - pchisq(G2,df) 
				object@G2 <- G2	
				object@p <- p
			}	
		}		
		object@logLik <- logLik
		object@SElogLik <- SElogLik		
		object@AIC <- AIC
		object@df <- as.integer(df)
		return(object)
	} 	
)

setMethod(
	f = "anova",
	signature = signature(object = 'polymirtClass'),
	definition = function(object, object2, ...){
		dots <- list(...)				
		nitems <- length(object@K)
		if(length(object@df) == 0 || length(object2@df) == 0) 
			stop('Use \'logLik\' to obtain likelihood values')  
		df <- object@df - object2@df 
		if(df < 0){
			df <- abs(df)
			tmp <- object
			object <- object2
			object2 <- tmp
		}
		X2 <- 2*object2@logLik - 2*object@logLik 
		AICdiff <- object@AIC - object2@AIC
		se <- round(object@SElogLik + object2@SElogLik,3)	
		cat("\nChi-squared difference: \n\nX2 = ", round(X2,3), 
			" (SE = ", se,"), df = ", df, ", p = ", round(1 - pchisq(X2,df),4), "\n", sep="")
		cat("AIC difference = ", round(AICdiff,3)," (SE = ", se,")\n", sep='')  
	}		
)

########################################
#Main Function

polymirt <- function(data, nfact, guess = 0, prev.cor = NULL, ncycles = 2000, 
	burnin = 100, SEM.cycles = 50, kdraws = 1, tol = .001, printcycles = TRUE,
	calcLL = TRUE, draws = 2000, debug = FALSE, ...)
{		
	Call <- match.call()   
	itemnames <- colnames(data)
	data <- as.matrix(data)		
	J <- ncol(data)
	N <- nrow(data)	
	if(length(guess) == 1) guess <- rep(guess,J)
	colnames(data) <- itemnames
	if(length(guess) > J || length(guess) < J) 
		stop("The number of guessing parameters is incorrect.")
	estGuess <- guess > 0					
	uniques <- list()
	for(i in 1:J)
		uniques[[i]] <- sort(unique(data[,i]))
	K <- rep(0,J)
	for(i in 1:J) K[i] <- length(uniques[[i]])	
	guess[K > 2] <- 0
	estGuess[K > 2] <- FALSE	
	itemloc <- cumsum(c(1,K))
	index <- 1:J	
	fulldata <- fulldata2 <- matrix(0,N,sum(K))
	Names <- NULL
	for(i in 1:J)
        Names <- c(Names, paste("Item.",i,"_",1:K[i],sep=""))				
	colnames(fulldata) <- Names			
	for(i in 1:J){
		ind <- index[i]
		if(setequal(uniques[[i]], c(0,1))){
			fulldata[ ,itemloc[ind]:(itemloc[ind]+1)] <- cbind(data[,ind],abs(1-data[,ind]))
			fulldata2[ ,itemloc[ind]:(itemloc[ind]+1)] <- cbind(abs(1-data[,ind]),data[,ind])
			next
		}
		dummy <- matrix(0,N,K[ind])
		for (j in 0:(K[ind]-1))  
			dummy[,j+1] <- as.integer(data[,ind] == uniques[[ind]][j+1])  		
		fulldata[ ,itemloc[ind]:(itemloc[ind+1]-1)] <- dummy		
		fulldata2[ ,itemloc[ind]:(itemloc[ind+1]-1)] <- dummy
	}	
	fulldata[is.na(fulldata)] <- fulldata2[is.na(fulldata2)] <- 0	
	if(!is.null(prev.cor)){
		if (ncol(prev.cor) == nrow(prev.cor)) Rpoly <- prev.cor
			else stop("Correlation matrix is not square.\n")
	} 	else Rpoly <- cormod(na.omit(data),K,guess)
	FA <- factor.minres(Rpoly,nfact,rotate = 'none', warnings= FALSE)	
	loads <- unclass(loadings(FA))
	u <- FA$unique
	u[u < .001 ] <- .2
	cs <- sqrt(u)
	lambdas <- loads/cs
	zetas <- rep(0,ncol(fulldata) - J)
	loc <- 1	
	for(i in 1:J){
		if(K[i] == 2){
			zetas[loc] <- qnorm(mean(fulldata[,itemloc[i]]))/cs[i]
			loc <- loc + 1
		} else {			
			temp <- table(data[,i])[1:(K[i]-1)]/N
			temp <- cumsum(temp)			
			zetas[loc:(loc+K[i]-2)] <- qnorm(1 - temp)/cs[i]	
			loc <- loc + K[i] - 1	
		}		
	}	
	npars <- length(c(lambdas,zetas)) + sum(estGuess) #start here
	parind <- 1:npars
	pars <- rep(NA,npars)
	Ksum <- cumsum(K + nfact - 1 + estGuess) - (nfact-1)
	lamind	<- gind <- c()	 
	for(i in 1:J){
		pars[Ksum[i]:(Ksum[i] + nfact - 1)] <- lambdas[i,]
		lamind <- c(lamind,Ksum[i]:(Ksum[i] + nfact - 1))
		if(estGuess[i]){
			pars[Ksum[i] - 2] <- guess[i]
			gind <- c(gind,Ksum[i] - 2)
		}	
	}	
	zetaind <- parind[is.na(pars)]			
	pars[is.na(pars)] <- zetas
	diag(Rpoly) <- 1	
	converge <- 1    	
	if(debug){
		print(lambdas)
		print(zetas)
	}	
	
    #preamble for MRHM algorithm			
	theta0 <- matrix(0,N,nfact)	
	cand.t.var <- 1	
	tmp <- .1
	for(i in 1:30){			
		theta0 <- draw.thetas(theta0,lambdas,zetas,guess,fulldata,K,itemloc,cand.t.var)
		if(i > 5){		
			if(attr(theta0,"Proportion Accepted") > .35) cand.t.var <- cand.t.var + 2*tmp 
			else if(attr(theta0,"Proportion Accepted") > .25 && nfact > 3) cand.t.var <- cand.t.var + tmp	
			else if(attr(theta0,"Proportion Accepted") < .2 && nfact < 4) cand.t.var <- cand.t.var - tmp
			else if(attr(theta0,"Proportion Accepted") < .1) cand.t.var <- cand.t.var - 2*tmp
			if (cand.t.var < 0){
				cand.t.var <- tmp		
				tmp <- tmp / 2
			}		
		}	
	} 
	m.thetas <- list()		
	SEM.stores <- matrix(0,SEM.cycles,npars)
	phi <- rep(0,npars)
	Tau <- info <- h <- matrix(0,npars,npars)
	m.list <- list()	  
	conv <- 0
	k <- 1	
	gamma <- 0.25
	startvalues <- pars
	stagecycle <- 1	
	
	for(cycles in 1:(ncycles + burnin + SEM.cycles))
	{ 
		if(cycles == burnin + 1) stagecycle <- 2
		if(stagecycle == 3)
			gamma <- (0.05/(cycles - SEM.cycles - burnin - 1))^(0.5) - .004
		if(cycles == (burnin + SEM.cycles + 1)){ 
			stagecycle <- 3		
		    pars <- rep(0,npars)
			for(i in 1:SEM.cycles) pars <- pars + SEM.stores[i,]
			pars <- pars/SEM.cycles	
			k <- kdraws	
			gamma <- 1
		}		
		lambdas <- matrix(pars[lamind],ncol=nfact,byrow=TRUE)
		zetas <- pars[zetaind]
		guess <- rep(0,J)
		guess[estGuess] <- pars[gind]		
		
		#Step 1. Generate m_k datasets of theta 
		for(j in 1:4) theta0 <- draw.thetas(theta0,lambdas,zetas,guess,fulldata,K,itemloc,cand.t.var)
		for(i in 1:k)			
			m.thetas[[i]] <- draw.thetas(theta0,lambdas,zetas,guess,fulldata,K,itemloc,cand.t.var)		
		theta0 <- m.thetas[[1]]
		
		#Step 2. Find average of simulated data gradients and hessian 
		g.m <- h.m <- list()					
		for(j in 1:k){
			g <- rep(NA,npars)
			loc <- 1
			for(i in 0:(J - 1)){
				if(estGuess[i+1]){
					temp <- dpars.dich(lambdas[i+1,],zetas[loc],guess[i+1],
						fulldata[,itemloc[i+1]],m.thetas[[j]], estGuess[i+1])
					ind <- parind[is.na(g)][1]
					ind2 <- ind+nfact+ estGuess[i+1]		
					g[ind:ind2] <- temp$grad
					h[ind:ind2,ind:ind2] <- temp$hess
					loc <- loc + 1
				} else {
					loc2 <- loc + K[i+1] - 2
					temp <- dpars.poly(lambdas[i+1,],zetas[loc:loc2],
						fulldata2[,itemloc[i+1]:(itemloc[i+2]-1)],m.thetas[[j]])
					ind <- parind[is.na(g)][1]	
					ind2 <- ind+nfact+K[i+1]-2
					g[ind:ind2] <- temp$grad
					h[ind:ind2,ind:ind2] <- temp$hess
					loc <- loc + K[i+1] - 1				
				}
			} 
			g.m[[j]] <- g
			h.m[[j]] <- h
		}
		ave.g <- rep(0,length(g))
		ave.h <- matrix(0,length(g),length(g))		
		for(i in 1:k){
		  ave.g <- ave.g + g.m[[i]]
		  ave.h <- ave.h + h.m[[i]]
		}
		grad <- ave.g/k
		ave.h <- (-1)*ave.h/k 
		if(printcycles){
			if((cycles + 1) %% 10 == 0){
				if(cycles < burnin)
					cat("Stage 1: Cycle = ", cycles + 1, ", Log-Lik = ", 
						sprintf("%.1f",attr(theta0,"log.lik")), sep="")
				if(cycles > burnin && cycles < burnin + SEM.cycles)
					cat("Stage 2: Cycle = ", cycles-burnin+1, ", Log-Lik = ",
						sprintf("%.1f",attr(theta0,"log.lik")), sep="")
				if(cycles > burnin + SEM.cycles)
					cat("Stage 3: Cycle = ", cycles-burnin-SEM.cycles+1, 
						", Log-Lik = ", sprintf("%.1f",attr(theta0,"log.lik")), sep="")				
			}
		}			
		if(stagecycle < 3){
		    correction <- SparseM::solve(ave.h) %*% grad					
			parsold <- pars
			correction[correction > .5] <- .5
			correction[correction < -0.5] <- -0.5	
			if(any(estGuess)) 
				correction[gind] <- 0											 
			pars <- pars + gamma*correction
			if(printcycles && (cycles + 1) %% 10 == 0){ 
				cat(", Max Change =", sprintf("%.4f",max(abs(gamma*correction))), "\n")
				flush.console()			
			}	
			pars[pars[gind] < 0] <- parsold[pars[gind] < 0]
			pars[pars[gind] > .4] <- parsold[pars[gind] > .4]	
			if(stagecycle == 2) SEM.stores[cycles - burnin,] <- pars
			next
		}	
		
		#Step 3. Update R-M step		
		Tau <- Tau + gamma*(ave.h - Tau)		
		correction <- SparseM::solve(Tau) %*% grad
		correction[correction > .5] <- .5
		correction[correction < -0.5] <- -0.5	
		if(any(estGuess))
			correction[gind] <- 0							
		if(printcycles && (cycles + 1) %% 10 == 0){ 
			cat(", gam = ",sprintf("%.3f",gamma),", Max Change = ", 
				sprintf("%.4f",max(abs(gamma*correction))), "\n", sep='')
			flush.console()			
		}	
		if(all(abs(parsold - pars) < tol)) conv <- conv + 1
			else conv <- 0	
		if(conv == 3) break		
		parsold <- pars
		pars <- pars + gamma*correction	
		pars[pars[gind] < 0] <- parsold[pars[gind] < 0]
		pars[pars[gind] > .4] <- parsold[pars[gind] > .4]
		
		#Extra: Approximate information matrix.	sqrt(diag(solve(info))) == SE		
		phi <- phi + gamma*(grad - phi)
		info <- info + gamma*(Tau - phi %*% t(phi) - info)		
	}
	cat("\n\n")	
	SE <- diag(solve(info))
	if(any(SE < 0)){
		warning("Information matrix is not positive definite.\n")
		SE <- rep(0,npars)
	}
	if(any(guess < 0)) warning("Negative lower asymptote parameter(s). \n")					
	SE <- sqrt(SE)	
	lambdas <- matrix(pars[lamind],ncol=nfact,byrow=TRUE)
	SElam <- matrix(SE[lamind],ncol=nfact,byrow=TRUE)
	SEg <- guess <- rep(NA,J)
	guess[estGuess] <- pars[gind]
	SEg[estGuess] <- SE[gind]
	zetas <- SEzeta <- matrix(NA,J,(max(K)-1))
	temp <- pars[zetaind]
	temp1 <- SE[zetaind]	
	k <- 1
	for(i in 1:J){
		for(j in 1:(K[i]-1)){
			zetas[i,j] <- temp[k] 
			SEzeta[i,j] <- temp1[k]
			k <- k + 1
		}
	}	 
	guess[K == 2 & !estGuess] <- 0
	pars <- cbind(lambdas,zetas)
	SEpars <- cbind(SElam,SEzeta,SEg)
	
	if (nfact > 1) norm <- sqrt(1 + rowSums(pars[ ,1:nfact]^2))
		else norm <- as.matrix(sqrt(1 + pars[ ,1]^2))  
	alp <- as.matrix(pars[ ,1:nfact]/norm)
	FF <- alp %*% t(alp)
	V <- eigen(FF)$vector[ ,1:nfact]
	L <- eigen(FF)$values[1:nfact]
	if (nfact == 1) F <- as.matrix(V * sqrt(L))
		else F <- V %*% sqrt(diag(L))  
	if (sum(F[ ,1] < 0)) F <- (-1) * F  
	h2 <- rowSums(F^2) 	
		
	mod <- new('polymirtClass',pars=pars, guess=guess, SEpars=SEpars, 
		cycles=cycles-SEM.cycles-burnin, Theta=theta0, fulldata=fulldata, 
		data=data, K=K, F=F, h2=h2, itemloc=itemloc, converge = converge, Call=Call)
	if(calcLL){
		cat("Calculating log-likelihood...\n")
		flush.console()
		mod <- logLik(mod,draws,...)		
	}	
	return(mod)	
}
